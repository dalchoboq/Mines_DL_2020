{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequential Prediction: Introduction to RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Today is about another widely used kind of neural networks: the Recurrent Neural Networks. They are used in many modern applications requiring to handle sequences of information, such as language translation or speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# I. A Sequential Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## I.1 What is sequential information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's consider a typical problem: you have an image of a ball in motion, like the following, can you predict where the ball will go next?\n",
    "\n",
    "![](images/ball_alone.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Unless you know newtonian physics better than any current scientist, you can not predict where the ball will go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But now assume that you have some previous positions of the ball as well, like in the following image, can you predict the direction?\n",
    "\n",
    "![](images/ball_with_previous.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sure you can, because you have a sequential information: not just a snapshot a given time, but **several snapshots** at different times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I.2 Examples of sequential problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You are playing everyday with sequential information, without even noticing it!\n",
    "\n",
    "For example, audio signals (music, speech, any sound...) are sequential information.\n",
    "\n",
    "![](images/Audio-Waveforms.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An audio signal is just a long list of numbers, they represent a sequence of amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another good example is what you are just reading... **a sentence is a sequence of words**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, there are numbers of sequential problems:\n",
    "* Language translation\n",
    "* speech recognition\n",
    "* music generation\n",
    "* sentiment classification\n",
    "* video activity\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## I.3 Limitations of classical approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's take a simple case. We have the following problem:\n",
    "\n",
    "![](images/cat_sentence.png)\n",
    "\n",
    "How would you solve it using machine learning and NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Idea 1**: a window of few previous words and one hot encoding:\n",
    "![](images/idea1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is a good idea, but what if we have long term dependencies, like in a sentence like the following:\n",
    "> \"I used to live in China when I was a kid, even though I'm French. That's why I speak fluent ...\"\n",
    "\n",
    "Would that work on this kind of sentence? Wouldn't it predict that the guy speaks French while it is meant to predict Chinese?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Idea 2**: a BOW:\n",
    "![](images/idea2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BOW and TF-IDF are powerful features. But they **do not preserve order** of the sequence. For a BOW, the two following sentences are the same:\n",
    "\n",
    "> \"The food is **good**, **not bad** at all!\"\n",
    "\n",
    "> \"The food is **bad**, **not good** at all!\"\n",
    "\n",
    "This is a serious issue when dealing with sentiment analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# II. RNN Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## II.1 Requirements to handle sequential information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To properly handle sequential information, here is what we would need to do:\n",
    "- handle variable length sequences\n",
    "- track long-term dependencies\n",
    "- keep information about order\n",
    "- share parameters across the sequence\n",
    "\n",
    "Well, **Recurrent Neural Networks (RNN)** can do most of it, let's see how!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.2 Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Up to now, you used to see diagrams where neural networks are going from left (with the features) to right (with the prediction).\n",
    "\n",
    "![](images/MLP_with_activations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When using recurrent neural networks, we will change this representation to the following:\n",
    "![](images/RNN_representation.png)\n",
    "\n",
    "Where in blue are the input features, in green here are the layers of the neural network, and in purple the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.3 Types of RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Depending on the problem to solve, many types of RNN can be used. Indeed, a sentiment analysis (one ouput) or a language translation (multiple output) have different requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/RNN_types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So to summarize:\n",
    "- A one-to-one is a MLP as you already know it\n",
    "- A many-to-many could be a translation model: it inputs a sequence of words in english and outputs a sequence of words in french\n",
    "- A many-to-one could be a sentiment analysis model: it inputs a sequence of words and outputs a review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## II.4 Hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before digging into the details of the computation, one more concept to add is the **hidden state**.\n",
    "\n",
    "![](images/hidden_state.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Actually, as you will see in the next section, a RNN has a two step computation. First, you compute a **hidden state** $h_t$ using both:\n",
    "- the input features $x_t$\n",
    "- the previous hidden state $h_{t-1}$\n",
    "\n",
    "After that only, you compute the prediction $\\hat{y}$ using this hidden state $h_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# III. RNN Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## III.1 Step-by-step computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, how does a RNN computes predictions?\n",
    "\n",
    "We will consider $x_1$, $x_2$, $x_3$... $x_t$ to be the words number 1, 2, 3... t of a sentence in english.\n",
    "\n",
    "The target $y_1$, $y_2$, $y_3$... $y_t$ are the words number 1, 2, 3... t of the same sentence in french.\n",
    "\n",
    "So our neural network will look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/RNN_ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a RNN, actually the same weights are shared for all steps of the sequence:\n",
    "\n",
    "![](images/RNN_ex3.png)\n",
    "\n",
    "The weights $W_{xh}$ and $W_{hh}$ will allow to compute the hidden state as a perceptron would do:\n",
    "\n",
    "$$\n",
    "\\large h_t = g(W_{hh} h_{t-1} + W_{xh} X_t + b)\n",
    "$$\n",
    "\n",
    "This is just like a perceptron, or a classical neural network, where $W_{xh} X_t$ is a weighted sum of features $X_t$, and $g$ is just an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the second step will be to compute the predictions $\\hat{y}$.\n",
    "\n",
    "![](images/RNN_ex4.png)\n",
    "\n",
    "This is where the weights $W_{hy}$ appear. Using those weights, this will again work just like a perceptron:\n",
    "\n",
    "$$\n",
    "\\large \\hat{y_t} = g(W_{hy} h_{t} + b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## III.2 Loss computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You might be wondering... how do we compute the loss in such a complicated network? And thus, what do we minimize with gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each time step is a regular neural network (a MLP). So, we can compute a loss for each time step, right?\n",
    "\n",
    "![](images/RNN_losses1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So that at each step *t*, we end up with a loss $L_t$. Then, sum them and you will have the global loss!\n",
    "![](images/RNN_losses2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# IV. Application to movie review analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## IV.1 Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The IMDB movie review dataset is a dataset containing review for movies, as well as an associated label 0 (negative review) or 1 (positive review).\n",
    "\n",
    "Let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import datasets\n",
    "imdb = datasets.imdb\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print('possible labels:', np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The train set is composed of 25000 samples. In each training sample, there is a list of numbers, corresponding to the output of a BOW with 10000 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Explore the dataset: you can make use of the function `imdb.get_word_index()` to get back to words and display some reviews. \n",
    "\n",
    "Be careful, the word indices `0`, `1`, `2` and `3` are reserved and mean no word in our dataset:\n",
    " - `0` stands for padding\n",
    " - `1` stands for start\n",
    " - `2` stands for unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# A dictionary mapping words to an integer index\n",
    "imdb = datasets.imdb\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly <UNK> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <UNK> with us all\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the training set actually is a sequence of words, encoded into numbers.\n",
    "\n",
    "The dataset is already preprocessed, which is highly convenient. But still, the sequences may not have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sequence 0: 218\n",
      "length of sequence 1: 189\n"
     ]
    }
   ],
   "source": [
    "print('length of sequence 0:', len(X_train[0]))\n",
    "print('length of sequence 1:', len(X_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will have to pad our training set. Because Keras currently does not support to have sequences of variable length.\n",
    "\n",
    "This is exactly what we did with images in CNN: we will add zeros so that all the sequences have the same length.\n",
    "\n",
    "But to choose a length for padding, it is first a good practice to look at the statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean length: 238.71364\n",
      "min length: 11\n",
      "max length: 2494\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lengths = []\n",
    "for seq in X_train:\n",
    "    lengths.append(len(seq))\n",
    "\n",
    "print(\"mean length:\", np.mean(lengths))    \n",
    "print(\"min length:\", np.min(lengths))    \n",
    "print(\"max length:\", np.max(lengths))    \n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now decide what length to keep, and check all sequences have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "                                 value=0,\n",
    "                                 padding='post', # to add zeros at the end\n",
    "                                 truncating='post', # to cut at the end\n",
    "                                 maxlen=128) # the length we want\n",
    "\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "                                value=0,\n",
    "                                padding='post', # to add zeros at the end\n",
    "                                truncating='post', # to cut at the end\n",
    "                                maxlen=128) # the length we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sequence 0: 128\n",
      "length of sequence 1: 128\n"
     ]
    }
   ],
   "source": [
    "print('length of sequence 0:', len(X_train[0]))\n",
    "print('length of sequence 1:', len(X_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## IV.2 Building a RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we will build a RNN to predict the labels. We can build a RNN with two layers and 8 units each. Finally we will add a sigmoid dense layer that computes the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "\n",
    "\n",
    "def my_RNN():\n",
    "\n",
    "    model = Sequential()\n",
    "    # The input_dim is the number of different words we have in our corpus: here 5000\n",
    "    # The input_length is the length of our sequences: here 128 thanks to padding\n",
    "    model.add(Embedding(input_dim=5000, output_dim=32, input_length=128))\n",
    "\n",
    "    # We add two layers of RNN \n",
    "    model.add(SimpleRNN(units=8, activation='relu', return_sequences=True))\n",
    "    model.add(SimpleRNN(units=8, activation='relu', return_sequences=False))\n",
    "    \n",
    "    # Finally we add a sigmoid\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Several things can be noticed here:\n",
    "- We have an `Embedding` layer: it converts our one hot encoding of words input into Word Embedding like numbers, so here basically each word is transformed into a 32 features array\n",
    "- We have stacked two `RNN` layers: this does not mean we are doing two RNN, this just means our neural network contains two layers\n",
    "- This first `RNN` has `return_sequences=True` and the second one has `return_sequences=False`: indeed the sequence is needed when another layer of `RNN` is added. The thumb rule for *many-to-one* is: `return_sequences=True` when there is another `RNN` layer, `return_sequences=False` otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you already know, we can then compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = my_RNN()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, let's train our RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 20s 801us/sample - loss: 0.6528 - accuracy: 0.5955 - val_loss: 0.5234 - val_accuracy: 0.7802\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 17s 684us/sample - loss: 0.4684 - accuracy: 0.8016 - val_loss: 0.4347 - val_accuracy: 0.8160\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 17s 677us/sample - loss: 0.3767 - accuracy: 0.8385 - val_loss: 0.4254 - val_accuracy: 0.8151\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 17s 685us/sample - loss: 0.3476 - accuracy: 0.8548 - val_loss: 0.4538 - val_accuracy: 0.7850\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 17s 685us/sample - loss: 0.3240 - accuracy: 0.8658 - val_loss: 0.4390 - val_accuracy: 0.8146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa55bb317d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train with NN: 0.88588\n",
      "accuracy on test with NN: 0.81456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('accuracy on train with NN:', model.evaluate(X_train, y_train, verbose=0)[1])\n",
    "print('accuracy on test with NN:', model.evaluate(X_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The accuracy is quite high for such a simple RNN: it took only a few lines of code and a couple of minutes to reach an accuracy greater than 80%!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
